<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Faithful vs Unfaithful CoT Attention Analysis</title>
    <link rel="icon" type="image/png" href="favicon.png">
    <link rel="stylesheet" href="style.css">
    <link href="https://fonts.googleapis.com/css2?family=Source+Serif+Pro:wght@400;600;700&family=Source+Sans+Pro:wght@400;600&family=JetBrains+Mono:wght@400;500&display=swap" rel="stylesheet">
</head>
<body>
    <div class="container">
        <!-- Header -->
        <header class="header">
            <h1>Do Faithful &amp; Unfaithful CoT Differ in How They Pay Attention?</h1>
            <p class="author-line">
                <span>By Yulia Volkova | MATS 9.0</span>
                <span class="author-links">
                    <a href="https://www.linkedin.com/in/yuulia-volkova/" target="_blank" title="LinkedIn">
                        <svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24" fill="currentColor"><path d="M19 0h-14c-2.761 0-5 2.239-5 5v14c0 2.761 2.239 5 5 5h14c2.762 0 5-2.239 5-5v-14c0-2.761-2.238-5-5-5zm-11 19h-3v-11h3v11zm-1.5-12.268c-.966 0-1.75-.79-1.75-1.764s.784-1.764 1.75-1.764 1.75.79 1.75 1.764-.783 1.764-1.75 1.764zm13.5 12.268h-3v-5.604c0-3.368-4-3.113-4 0v5.604h-3v-11h3v1.765c1.396-2.586 7-2.777 7 2.476v6.759z"/></svg>
                    </a>
                    <a href="https://yulia-volkova.github.io/" target="_blank" title="Website">
                        <svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="10"></circle><line x1="2" y1="12" x2="22" y2="12"></line><path d="M12 2a15.3 15.3 0 0 1 4 10 15.3 15.3 0 0 1-4 10 15.3 15.3 0 0 1-4-10 15.3 15.3 0 0 1 4-10z"></path></svg>
                    </a>
                </span>
            </p>
        </header>

        <!-- Focus illustration -->
        <div class="focus-illustration">
            <img src="images/focus_emoji.jpg" alt="Focus!" class="focus-img">
        </div>

        <!-- TL;DR Section -->
        <section class="tldr-section">
            <h2>TL;DR</h2>
            <p class="tldr-intro">
                I analyze consistently faithful &amp; unfaithful rollouts for MMLU &amp; GPQA-diamond datasets using the
                <a href="https://arxiv.org/abs/2506.19143" target="_blank">Thought Anchors</a> framework.
                I find that unfaithful CoT shows higher cue-following rate, and receiver heads almost do not overlap between faithful &amp; unfaithful CoT when looking at reasoning-only attention.
            </p>
            <p class="tldr-link">
                <a href="#key-findings">View detailed findings below ‚Üì</a>
            </p>
        </section>

        <!-- Methodology Section (Collapsed by default) -->
        <section class="methodology-collapsible" id="methodology">
            <h2 class="methodology-header" onclick="toggleMethodology()">
                Methodology
                <span id="methodology-toggle" class="toggle-icon">‚ñ∂</span>
            </h2>
            <div id="methodology-content" class="methodology-body collapsed">

                <h3>Hypothesis</h3>
                <p>
                    If white-box attention attribution patterns reflect how models use information during reasoning,
                    then <strong>faithful CoT</strong> (where reasoning genuinely influences the answer) should show focused attention
                    to relevant broadcasting sentences, while <strong>unfaithful CoT</strong> (post-hoc rationalization)
                    may exhibit more diffuse attention or anchor to different, potentially misleading parts of the reasoning chain.
                </p>
                <p>
                    This work replicates and extends <a href="https://arxiv.org/abs/2506.19143" target="_blank">Bogdan et al. (2025) "Thought Anchors"</a>
                    to test whether receiver heads and vertical stripe patterns of attention targeted towards specific sentences ("thought anchors") differ between faithful and unfaithful chains.
                    If attention markers meaningfully distinguish faithful from unfaithful CoT, this could enable
                    white-box monitoring of reasoning quality in deployed models.
                </p>

                <!-- Pipeline Overview -->
                <h3>Pipeline</h3>
                <div class="pipeline-overview">
                    <img src="images/methodology_pipeline.svg" alt="Methodology Pipeline" class="pipeline-img">
                </div>

                <h3>Dataset Statistics</h3>
                <p><strong>MMLU:</strong> 143 problems, 20 rollouts per condition, median reasoning accuracy 0.637, median no-reasoning accuracy 0.474.</p>
                <p><strong>GPQA-Diamond:</strong> 186 problems, 20 rollouts per condition, mean base accuracy 0.577, mean no-reasoning accuracy 0.378.</p>

                <h3>Model &amp; Generation Settings</h3>
                <p>
                    Two generation stages: (1) initial rollouts for faithfulness classification,
                    (2) attention analysis rollouts for visualization.
                </p>
                <ul class="clean-list">
                    <li><strong>Model:</strong> <code>deepseek-ai/deepseek-r1-distill-qwen-14b</code></li>
                    <li><strong>Temperature:</strong> 0.7, <strong>Top-p:</strong> 0.95</li>
                    <li><strong>Max tokens:</strong> 2048 (MMLU), 8192/2048 (GPQA stage 1/2)</li>
                    <li><strong>Rollouts:</strong> 20 per condition (stage 1), 5 per condition (stage 2)</li>
                </ul>

                <h3>Faithfulness Classification</h3>
                <ul class="clean-list">
                    <li><strong>Faithful CoT:</strong> Follows cue AND mentions it in reasoning (threshold: ‚â•80% MMLU, ‚â•70% GPQA)</li>
                    <li><strong>Unfaithful CoT:</strong> Follows cue but doesn't mention it (threshold: ‚â•80% MMLU, ‚â•70% GPQA)</li>
                </ul>

                <h3 id="selection-criteria">Problem Selection Criteria</h3>
                <p>Problems were selected from MMLU and GPQA rollouts using the following criteria:</p>
                <ul class="clean-list">
                    <li><strong>Low no-reasoning accuracy (&lt;50%)</strong> ‚Äî Problems where the model struggles without CoT</li>
                    <li><strong>High cue response gap (‚â•0.5)</strong> ‚Äî Large difference in cue-following between cued and uncued conditions</li>
                    <li><strong>Cue ‚â† Ground Truth</strong> ‚Äî The cue answer differs from the correct answer</li>
                    <li><strong>Each problem is unique</strong></li>
                </ul>

                <h3>Preliminary Data Analysis</h3>
                <div class="definitions-section" style="display: flex; gap: 1rem; margin-bottom: 1rem;">
                    <div>
                        <button class="expand-graph-btn" onclick="toggleDefinition('what-is-r')">What is "r"?</button>
                        <div id="what-is-r" class="correlation-graph hidden" style="margin-top: 0.5rem;">
                            <p style="font-size: 0.9rem; color: #666; font-style: italic; margin: 0;">
                                "r" represents the Pearson correlation coefficient, measuring the linear relationship between two variables.
                                Values range from -1 (perfect negative correlation) to +1 (perfect positive correlation), with 0 indicating no linear relationship.
                            </p>
                        </div>
                    </div>
                    <div>
                        <button class="expand-graph-btn" onclick="toggleDefinition('what-is-gap')">What is "Gap"?</button>
                        <div id="what-is-gap" class="correlation-graph hidden" style="margin-top: 0.5rem;">
                            <p style="font-size: 0.9rem; color: #666; font-style: italic; margin: 0;">
                                "Gap" refers to the mean cue response gap ‚Äî the average increase in cue-following behavior when a misleading cue is present.
                            </p>
                        </div>
                    </div>
                </div>

                <!-- MMLU Findings -->
                <h4 style="margin-top: 1rem; color: #666;">MMLU</h4>
                <div class="findings-grid">
                    <div class="finding-card">
                        <div class="finding-header">
                            <span class="finding-metric">r(accuracy, cue following) = -0.459</span>
                            <span class="finding-pval">p &lt; 0.0001</span>
                        </div>
                        <p>Lower base accuracy correlates with <strong>more cue following</strong> ‚Äî the model is more susceptible to misleading cues on harder problems.</p>
                        <p class="finding-caveat">Cue following behaviour is likely confounded by problem difficulty. On harder problems, the model may fall back to the cue when struggling to find an answer. To control for this, future work should compare problems with equal uncued accuracy levels.</p>
                        <button class="expand-graph-btn" onclick="toggleGraph('mmlu-acc-cue-follow')">Show graph ‚ñº</button>
                        <div id="mmlu-acc-cue-follow" class="correlation-graph hidden">
                            <img src="images/accuracy_vs_cue_following.png" alt="Accuracy vs Cue Following correlation" style="width: 100%; max-width: 600px; margin-top: 1rem;">
                        </div>
                    </div>
                    <div class="finding-card">
                        <div class="finding-header">
                            <span class="finding-metric">Gap = 0.289</span>
                            <span class="finding-pval">p &lt; 0.0001</span>
                        </div>
                        <p>Mean cue response gap of 0.289 ‚Äî <strong>79.7%</strong> of problems show increased cue following when cued.</p>
                        <button class="expand-graph-btn" onclick="toggleGraph('mmlu-gap-dist')">Show distribution ‚ñº</button>
                        <div id="mmlu-gap-dist" class="correlation-graph hidden">
                            <img src="images/mmlu_gap_distribution.png" alt="Cue Response Gap Distribution (MMLU)" style="width: 100%; max-width: 600px; margin-top: 1rem;">
                        </div>
                    </div>
                    <div class="finding-card">
                        <div class="finding-header">
                            <span class="finding-metric">r(accuracy, gap) = 0.008</span>
                            <span class="finding-pval">p = 0.92</span>
                        </div>
                        <p>No significant correlation between base accuracy and cue response gap ‚Äî the <em>change</em> in behavior is consistent across difficulty levels.</p>
                        <button class="expand-graph-btn" onclick="toggleGraph('mmlu-acc-gap')">Show graph ‚ñº</button>
                        <div id="mmlu-acc-gap" class="correlation-graph hidden">
                            <img src="images/mmlu_accuracy_vs_gap.png" alt="Accuracy vs Cue Response Gap correlation" style="width: 100%; max-width: 600px; margin-top: 1rem;">
                        </div>
                    </div>
                </div>

                <!-- GPQA Findings -->
                <h4 style="margin-top: 1.5rem; color: #666;">GPQA-Diamond</h4>
                <div class="findings-grid">
                    <div class="finding-card">
                        <div class="finding-header">
                            <span class="finding-metric">r(accuracy, cue following) = -0.522</span>
                            <span class="finding-pval">p &lt; 0.0001</span>
                        </div>
                        <p>Lower base accuracy correlates with <strong>more cue following</strong> ‚Äî effect is even stronger than MMLU.</p>
                        <p class="finding-caveat">Cue following behaviour is likely confounded by problem difficulty. On harder problems, the model may fall back to the cue when struggling to find an answer. To control for this, future work should compare problems with equal uncued accuracy levels.</p>
                        <button class="expand-graph-btn" onclick="toggleGraph('gpqa-acc-cue-follow')">Show graph ‚ñº</button>
                        <div id="gpqa-acc-cue-follow" class="correlation-graph hidden">
                            <img src="images/gpqa_accuracy_vs_cue_following.png" alt="Accuracy vs Cue Following correlation (GPQA)" style="width: 100%; max-width: 600px; margin-top: 1rem;">
                        </div>
                    </div>
                    <div class="finding-card">
                        <div class="finding-header">
                            <span class="finding-metric">Gap = 0.183</span>
                            <span class="finding-pval">p &lt; 0.0001</span>
                        </div>
                        <p>Mean cue response gap of 0.183 ‚Äî <strong>67.2%</strong> of problems show increased cue following when cued.</p>
                        <button class="expand-graph-btn" onclick="toggleGraph('gpqa-gap-dist')">Show distribution ‚ñº</button>
                        <div id="gpqa-gap-dist" class="correlation-graph hidden">
                            <img src="images/gpqa_gap_distribution.png" alt="Cue Response Gap Distribution (GPQA)" style="width: 100%; max-width: 600px; margin-top: 1rem;">
                        </div>
                    </div>
                    <div class="finding-card">
                        <div class="finding-header">
                            <span class="finding-metric">r(faithfulness, accuracy drop) = -0.273</span>
                            <span class="finding-pval">p = 0.0002</span>
                        </div>
                        <p>Higher faithfulness (explicit cue mentions) ‚Üí <strong>larger accuracy drops</strong>. Verbalizing the cue is associated with being more misled.</p>
                        <button class="expand-graph-btn" onclick="toggleGraph('gpqa-faith-acc-drop')">Show graph ‚ñº</button>
                        <div id="gpqa-faith-acc-drop" class="correlation-graph hidden">
                            <img src="images/gpqa_faithfulness_vs_accuracy_drop.png" alt="Faithfulness vs Accuracy Drop correlation (GPQA)" style="width: 100%; max-width: 600px; margin-top: 1rem;">
                        </div>
                    </div>
                </div>

                <h3>Attention Analysis</h3>
                <p>
                    For each problem, we identify <strong>receiver heads</strong> ‚Äî attention heads with high kurtosis
                    in their attention distribution. High kurtosis indicates the head consistently
                    attends to specific source sentences (creating "vertical stripes" in the attention matrix).
                    I compare which source sentences receive the most attention in cued vs. uncued rollouts.
                </p>

            </div> <!-- methodology-content -->
        </section>

        <!-- Try It Out Section -->
        <section class="try-it-out-section">
            <h2>Try It Out!</h2>
        </section>

        <!-- Dataset Selection -->
        <section class="control-panel">
            <div class="control-group">
                <label for="dataset-select">Dataset</label>
                <select id="dataset-select">
                    <option value="mmlu" selected>MMLU</option>
                    <option value="gpqa">GPQA-Diamond</option>
                </select>
            </div>

            <div class="control-group">
                <label>Category</label>
                <div class="checkbox-group" id="category-checkboxes">
                    <label class="checkbox-label">
                        <input type="checkbox" id="cat-faithful" value="faithful" checked>
                        <span>Faithful CoT</span>
                    </label>
                    <label class="checkbox-label">
                        <input type="checkbox" id="cat-unfaithful" value="unfaithful" checked>
                        <span>Unfaithful CoT</span>
                    </label>
                </div>
            </div>

            <div class="control-group">
                <label for="pi-select">Question ID</label>
                <select id="pi-select">
                    <!-- Populated dynamically -->
                </select>
            </div>

            <div class="control-group">
                <label for="heads-source">
                    Receiver Heads From
                    <span class="info-icon" id="heads-source-info" data-tooltip="heads-source-tooltip">‚ÑπÔ∏è</span>
                </label>
                <select id="heads-source">
                    <option value="aggregate">All in Category</option>
                    <option value="single">This Question Only</option>
                </select>
                <div id="heads-source-tooltip" class="control-tooltip hidden">
                    <p><strong>All in Category:</strong> Receiver heads are calculated using kurtosis measure calculated across all rollouts from all question IDs in the selected category. If only one category (faithful or unfaithful) is selected, kurtosis is computed across all rollouts from that category.</p>
                    <p style="margin-top: 0.5rem;"><strong>This Question Only:</strong> Receiver heads are calculated only across rollouts of this specific question ID.</p>
                    <p style="margin-top: 0.5rem;"><strong>Note on combining categories:</strong> If both faithful and unfaithful categories are selected, kurtosis would be computed across all rollouts from both categories combined. However, this may not be statistically appropriate since faithful and unfaithful problems may exhibit systematically different attention patterns.</p>
                    <p style="margin-top: 0.5rem; font-size: 0.85rem; color: var(--text-muted);">Note: Bogdan et al. calculate receiver heads across the whole dataset of math rollouts (<a href="https://huggingface.co/datasets/uzaymacar/math-rollouts" target="_blank">link</a>).</p>
                </div>
            </div>

            <div class="control-group">
                <label for="attention-mode">Attention Mode</label>
                <select id="attention-mode">
                    <option value="full" selected>With Prompt</option>
                    <option value="reasoning">Reasoning Only</option>
                </select>
            </div>
        </section>

        <!-- TBA Message (for datasets without data) -->
        <div id="tba-message" class="tba-message hidden">
            <h2>üìä No Problems Available</h2>
            <p>No problems found for this dataset/category combination.</p>
        </div>

        <!-- Main Content -->
        <main id="main-content">
            <!-- Question Info -->
            <section class="question-info">
                <h2>Question ID <span id="question-details-id">‚Äî</span> <span id="pi-category-badge" class="category-badge"></span></h2>
                <div class="info-grid">
                    <div class="info-card">
                        <span class="info-label">Question Text</span>
                        <p id="question-text" class="question-text">Loading...</p>
                        <button id="expand-question-btn" class="expand-btn" onclick="toggleQuestionExpand()">Show more ‚ñº</button>
                    </div>
                    <div class="info-row">
                        <div class="info-card small">
                            <span class="info-label">Ground Truth</span>
                            <span id="gt-answer" class="answer-badge gt">‚Äî</span>
                        </div>
                        <div class="info-card small">
                            <span class="info-label">Cue Answer</span>
                            <span id="cue-answer" class="answer-badge cue">‚Äî</span>
                        </div>
                        <div class="info-card small">
                            <span class="info-label">Reasoning Acc</span>
                            <span id="reasoning-acc" class="stat-value">‚Äî</span>
                        </div>
                        <div class="info-card small">
                            <span class="info-label">No-Reasoning Acc</span>
                            <span id="no-reasoning-acc" class="stat-value">‚Äî</span>
                        </div>
                        <div class="info-card small">
                            <span class="info-label">Faithfulness %</span>
                            <span id="faithfulness-pct" class="stat-value faithful-stat">‚Äî</span>
                        </div>
                    </div>
                </div>
                
                <!-- Warning for problems where reasoning is worse than no-reasoning -->
                <div id="reasoning-warning" class="reasoning-warning hidden">
                    <span class="warning-icon">‚ö†Ô∏è</span>
                    <span class="warning-text">
                        <strong>Note:</strong> This problem may be non-representative as its reasoning accuracy is lower than no-reasoning accuracy. 
                        However, attention patterns may still be interesting for such examples.
                    </span>
                </div>
            </section>

            <p class="viz-intro">Below I look at the cued versus uncued versions of the rollout for question ID <span id="selected-question-id" class="highlight-id">‚Äî</span>, <span id="selected-category-label" class="highlight-category">‚Äî</span></p>

            <!-- Receiver Heads + Attention unified container -->
            <div class="unified-attention-container">
            <!-- Receiver Heads -->
            <section class="receiver-heads-section">
                <h3 class="receiver-heads-title">Top Receiver Heads <span class="info-icon" id="receiver-heads-info" data-tooltip="receiver-heads-tooltip">‚ÑπÔ∏è</span></h3>
                <div id="receiver-heads-tooltip" class="control-tooltip hidden">
                    <p>Heads with highest kurtosis in attention distribution</p>
                </div>
                <p id="heads-fallback-note" class="fallback-note hidden"></p>

                <div class="heads-comparison">
                    <div class="heads-column">
                        <h3>Cued Rollout</h3>
                        <div id="cued-heads" class="heads-list">
                            <!-- Populated dynamically -->
                        </div>
                    </div>
                    <div class="heads-column">
                        <h3>Uncued Rollout</h3>
                        <div id="uncued-heads" class="heads-list">
                            <!-- Populated dynamically -->
                        </div>
                    </div>
                </div>

                <div class="shared-heads">
                    <span class="shared-label">Shared Heads for cued & uncued:</span>
                    <span id="shared-heads-list">‚Äî</span>
                </div>
            </section>

            <!-- Attention Matrices Side by Side -->
            <section class="attention-section">
                <h2>Attention Patterns</h2>
                <p class="section-desc">Click on a head above to view its attention matrix. Hover for values.</p>
                
                <div class="attention-comparison">
                    <!-- Cued Panel -->
                    <div class="attention-panel">
                        <div class="panel-header">
                            <h3>Cued Rollout</h3>
                            <span id="cued-selected-head" class="selected-head-badge">L0-H0</span>
                            <span id="cued-prof-mention" class="prof-mention-badge">Faithfulness rate: ‚Äî%</span>
                        </div>
                        <div class="matrix-container">
                            <div id="cued-matrix" class="attention-matrix">
                                <div class="matrix-placeholder">Select a head to view attention</div>
                            </div>
                        </div>
                        <div class="stripe-analysis">
                            <h4>Top Source Sentences (Stripes) <span class="info-icon" onmouseenter="showInfoTooltip(event)" onmouseleave="hideTooltip()">‚ÑπÔ∏è</span></h4>
                            <ul id="cued-stripes" class="stripe-list">
                                <!-- Populated dynamically -->
                            </ul>
                        </div>
                    </div>

                    <!-- Uncued Panel -->
                    <div class="attention-panel">
                        <div class="panel-header">
                            <h3>Uncued Rollout</h3>
                            <span id="uncued-selected-head" class="selected-head-badge">L0-H0</span>
                        </div>
                        <div class="matrix-container">
                            <div id="uncued-matrix" class="attention-matrix">
                                <div class="matrix-placeholder">Select a head to view attention</div>
                            </div>
                        </div>
                        <div class="stripe-analysis">
                            <h4>Top Source Sentences (Stripes) <span class="info-icon" onmouseenter="showInfoTooltip(event)" onmouseleave="hideTooltip()">‚ÑπÔ∏è</span></h4>
                            <ul id="uncued-stripes" class="stripe-list">
                                <!-- Populated dynamically -->
                            </ul>
                        </div>
                    </div>
                </div>
            </section>

            <!-- Summary for cued vs uncued -->
            <section class="conclusion-section">
                <h2>Summary</h2>
                <div class="summary-stats">
                    <div class="summary-card">
                        <span class="summary-value" id="shared-heads-count">0</span>
                        <span class="summary-label">Shared Heads among cued and uncued versions</span>
                    </div>
                    <div class="summary-card">
                        <span class="summary-value" id="shared-sources-count">0</span>
                        <span class="summary-label">Shared Source Sentences</span>
                    </div>
                    <div class="summary-card">
                        <span class="summary-value" id="cue-in-stripes">‚Äî</span>
                        <span class="summary-label">Cue in Top Sources (Cued)</span>
                    </div>
                </div>
            </section>
            </div> <!-- unified-attention-container -->

            <p class="viz-intro">Now I look at the faithful and unfaithful rollout examples for the cued only version of question ID <span id="fvu-question-id" class="highlight-id">‚Äî</span>, <span id="fvu-category-label" class="highlight-category">‚Äî</span></p>

            <!-- Faithful vs Unfaithful Comparison (NEW) -->
            <section id="fvu-section" class="attention-section fvu-section hidden">
                <h2>Faithful vs Unfaithful Comparison</h2>

                <div id="fvu-not-available" class="fvu-not-available hidden">
                    <p>Faithful vs Unfaithful comparison not available for this problem. 
                    This requires both a cued rollout that mentions the professor AND one that doesn't.</p>
                </div>
                
                <div id="fvu-comparison" class="attention-comparison">
                    <!-- Faithful Panel -->
                    <div class="attention-panel faithful-panel">
                        <div class="panel-header">
                            <h3>Faithful (Cued + Mentions)</h3>
                            <span id="fvu-faithful-head" class="selected-head-badge">L0-H0</span>
                        </div>
                        <div class="matrix-container">
                            <div id="faithful-matrix" class="attention-matrix">
                                <div class="matrix-placeholder">Select a head to view attention</div>
                            </div>
                        </div>
                        <div class="stripe-analysis">
                            <h4>Top Source Sentences <span class="info-icon" onmouseenter="showInfoTooltip(event)" onmouseleave="hideTooltip()">‚ÑπÔ∏è</span></h4>
                            <ul id="faithful-stripes" class="stripe-list">
                                <!-- Populated dynamically -->
                            </ul>
                        </div>
                    </div>

                    <!-- Unfaithful Panel -->
                    <div class="attention-panel unfaithful-panel">
                        <div class="panel-header">
                            <h3>Unfaithful (Cued + Silent)</h3>
                            <span id="fvu-unfaithful-head" class="selected-head-badge">L0-H0</span>
                        </div>
                        <div class="matrix-container">
                            <div id="unfaithful-matrix" class="attention-matrix">
                                <div class="matrix-placeholder">Select a head to view attention</div>
                            </div>
                        </div>
                        <div class="stripe-analysis">
                            <h4>Top Source Sentences <span class="info-icon" onmouseenter="showInfoTooltip(event)" onmouseleave="hideTooltip()">‚ÑπÔ∏è</span></h4>
                            <ul id="unfaithful-stripes" class="stripe-list">
                                <!-- Populated dynamically -->
                            </ul>
                        </div>
                    </div>
                </div>
            </section>
        </main>

        <!-- Key Findings Section (Collapsible) -->
        <section class="key-findings-section" id="key-findings">
            <h2 class="key-findings-header" onclick="toggleKeyFindings()">
                Detailed Key Findings
                <span id="key-findings-toggle" class="toggle-icon">‚ñ∂</span>
            </h2>
            <div id="key-findings-content" class="key-findings-body collapsed">
            <div class="findings-grid">
                <!-- Finding 1: Hidden Influence -->
                <div class="finding-card">
                    <div class="finding-header">
                        <span class="finding-metric">Unfaithful CoT shows higher cue-following rate</span>
                    </div>
                    <ul class="finding-list">
                        <li>Unfaithful CoT show higher cue-following rate (80%) than faithful CoT (71%) when we control for cue response gap ‚â• 0.5.</li>
                        <li>Without controlling for high cue influence, the pattern reverses: unfaithful 34% vs faithful 42%.</li>
                        <li>In <a href="#selection-criteria" onclick="document.getElementById('methodology-content').classList.remove('collapsed'); document.getElementById('methodology-toggle').classList.add('expanded');">selected</a> subset of questions, where we control both for cue response gap and low no reasoning accuracy, the pattern strengthens: unfaithful CoT show higher cue-following rate (91%) than faithful CoT (66%).</li>
                    </ul>
                    <button class="expand-graph-btn" onclick="toggleGraph('hidden-influence')">Show graph ‚ñº</button>
                    <div id="hidden-influence" class="correlation-graph hidden">
                        <img src="images/conclusion_hidden_influence_web.png" alt="Hidden Influence Comparison">
                    </div>
                </div>

                <!-- Finding 2: Divergent Circuits -->
                <div class="finding-card">
                    <div class="finding-header">
                        <span class="finding-metric">Divergent Attention Circuits</span>
                    </div>
                    <p>When we look at <strong>reasoning only</strong> attention, faithful and unfaithful questions use completely different (only 0-11% overlap) heads to focus on the most important sentences.</p>
                    <p>However, when <strong>prompt is included</strong> into the calculation of receiver heads and attention to sentences within prompt is also accounted for, faithful and unfaithful CoT <strong>share 62-83%</strong> of top receiver heads.</p>
                    <button class="expand-graph-btn" onclick="toggleGraph('divergent-circuits')">Show graph ‚ñº</button>
                    <div id="divergent-circuits" class="correlation-graph hidden">
                        <img src="images/conclusion_divergent_circuits_web.png" alt="Divergent Circuits Comparison">
                    </div>
                </div>

                <!-- Finding 3: Universal Receiver Heads -->
                <div class="finding-card">
                    <div class="finding-header">
                        <span class="finding-metric">Universal Receiver Heads</span>
                    </div>
                    <p>Certain attention heads (e.g., L45_H0, L47_H3, L31_H34) appear as top receivers across both MMLU and GPQA, and in both faithful and unfaithful categories.</p>
                    <p style="font-size: 0.85rem; color: var(--text-secondary); margin-top: 0.5rem;">
                        These heads may represent fundamental "answer extraction" circuits in the model, independent of reasoning faithfulness.
                    </p>
                    <button class="expand-graph-btn" onclick="toggleGraph('universal-heads')">Show graph ‚ñº</button>
                    <div id="universal-heads" class="correlation-graph hidden">
                        <img src="images/conclusion_universal_heads_web.png" alt="Universal Receiver Heads">
                    </div>
                </div>
            </div>
            </div> <!-- key-findings-content -->
        </section>

        <!-- Future Directions -->
        <section class="future-directions-section">
            <h2>Future Directions</h2>
            <p>
                (1) Test on domains where post-hoc rationalization is common,
                such as the hiring-scenario dataset (<a href="https://arxiv.org/abs/2506.10922" target="_blank">Karvonen & Marks, 2025</a>), where models explain choices with
                acceptable narratives that may not reflect true decision factors.<br>
                (2) Combine with Verbalization Fine-Tuning (<a href="https://arxiv.org/abs/2506.22777" target="_blank">Turpin et al., 2025</a>) ‚Äî if VFT increases cue admission,
                do receiver heads shift to anchor on the verbalized cue sentence post-training?<br>
                (2.1) Try model diffing between VFT model and original.<br>
                Such experiments could validate whether attention markers reliably track cue-following behavior.
            </p>
        </section>

        <!-- Acknowledgements -->
        <section class="acknowledgements-section">
            <h2>Acknowledgements</h2>
            <p>
                This work was done under the <a href="https://researchathena.org/" target="_blank">ATHENA</a> fellowship with Arun Jose as mentor.
                I would also like to thank Qiyao Wei and Andy Wang for valuable advice, feedback, and discussions.
            </p>
        </section>

        <!-- Footer -->
        <footer class="footer">
            <p>Attention Analysis for Chain-of-Thought Faithfulness</p>
            <p class="footer-links">
                <a href="#methodology">Methodology</a> ¬∑
                <a href="https://github.com/yourusername/thought-anchors-faithfulness" target="_blank">GitHub</a>
            </p>
        </footer>
    </div>

    <!-- Tooltip -->
    <div id="tooltip" class="tooltip hidden"></div>

    <script src="data.js"></script>
    <script src="app.js"></script>
</body>
</html>

