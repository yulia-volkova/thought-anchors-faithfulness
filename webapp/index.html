<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Faithful vs Unfaithful CoT Attention Analysis</title>
    <link rel="stylesheet" href="style.css">
    <link href="https://fonts.googleapis.com/css2?family=Source+Serif+Pro:wght@400;600;700&family=Source+Sans+Pro:wght@400;600&family=JetBrains+Mono:wght@400;500&display=swap" rel="stylesheet">
</head>
<body>
    <div class="container">
        <!-- Header -->
        <header class="header">
            <h1>Do Faithful &amp; Unfaithful CoT Differ in How They Pay Attention?</h1>
            <p class="subtitle">Interactive visualization of attention patterns in chain-of-thought reasoning</p>
        </header>

        <!-- Hypothesis -->
        <section class="hypothesis-section">
            <h2>Hypothesis</h2>
            <p class="hypothesis-text">
                If white-box attention attribution patterns reflect how models use information during reasoning,
                then <strong>faithful CoT</strong> (where reasoning genuinely influences the answer) should show focused attention
                to relevant broadcasting sentences, while <strong>unfaithful CoT</strong> (post-hoc rationalization)
                may exhibit more diffuse attention or anchor to different, potentially misleading parts of the reasoning chain.
            </p>
            <p class="hypothesis-text" style="margin-top: 0.75rem; font-style: normal; font-size: 0.95rem; color: var(--text-secondary);">
                This work replicates and extends <a href="https://arxiv.org/abs/2506.19143" target="_blank" style="color: var(--accent-cued);">Bogdan et al. (2025) "Thought Anchors"</a>
                to test whether receiver heads and vertical stripe patterns of attention targeted towards specific sentences ("thought anchors") differ between faithful and unfaithful chains.
                If attention markers meaningfully distinguish faithful from unfaithful CoT, this could enable
                white-box monitoring of reasoning quality in deployed models.
            </p>
        </section>

        <!-- Dataset Selection -->
        <section class="control-panel">
            <div class="control-group">
                <label for="dataset-select">Dataset</label>
                <select id="dataset-select">
                    <option value="mmlu" selected>MMLU</option>
                    <option value="gpqa">GPQA-Diamond</option>
                </select>
            </div>

            <div class="control-group">
                <label>Category</label>
                <div class="checkbox-group" id="category-checkboxes">
                    <label class="checkbox-label">
                        <input type="checkbox" id="cat-faithful" value="faithful" checked>
                        <span>Faithful CoT</span>
                    </label>
                    <label class="checkbox-label">
                        <input type="checkbox" id="cat-unfaithful" value="unfaithful" checked>
                        <span>Unfaithful CoT</span>
                    </label>
                </div>
            </div>

            <div class="control-group">
                <label for="pi-select">Problem ID (PI)</label>
                <select id="pi-select">
                    <!-- Populated dynamically -->
                </select>
            </div>

            <div class="control-group">
                <label for="heads-source">
                    Receiver Heads From
                    <span class="info-icon" id="heads-source-info" data-tooltip="heads-source-tooltip">‚ÑπÔ∏è</span>
                </label>
                <select id="heads-source">
                    <option value="aggregate">All in Category</option>
                    <option value="single">This PI Only</option>
                </select>
                <div id="heads-source-tooltip" class="control-tooltip hidden">
                    <p><strong>All in Category:</strong> Receiver heads are calculated using kurtosis measure calculated across all rollouts from all problem IDs (PIs) in the selected category. If only one category (faithful or unfaithful) is selected, kurtosis is computed across all rollouts from that category.</p>
                    <p style="margin-top: 0.5rem;"><strong>Note on combining categories:</strong> If both faithful and unfaithful categories are selected, kurtosis would be computed across all rollouts from both categories combined. However, this may not be statistically appropriate since faithful and unfaithful problems may exhibit systematically different attention patterns. The original analysis keeps them separate for comparison.</p>
                    <p style="margin-top: 0.5rem;"><strong>This PI Only:</strong> Receiver heads are calculated only across rollouts of this specific problem ID (PI).</p>
                    <p style="margin-top: 0.5rem; font-size: 0.85rem; color: var(--text-muted);">Note: Bogdan et al. calculate receiver heads across the whole dataset of math rollouts (<a href="https://huggingface.co/datasets/uzaymacar/math-rollouts" target="_blank">link</a>).</p>
                </div>
            </div>

            <div class="control-group">
                <label for="attention-mode">Attention Mode</label>
                <select id="attention-mode">
                    <option value="full" selected>With Prompt</option>
                    <option value="reasoning">Reasoning Only</option>
                </select>
            </div>
        </section>

        <!-- TBA Message (for datasets without data) -->
        <div id="tba-message" class="tba-message hidden">
            <h2>üìä No Problems Available</h2>
            <p>No problems found for this dataset/category combination.</p>
        </div>

        <!-- Main Content -->
        <main id="main-content">
            <!-- Question Info -->
            <section class="question-info">
                <h2>Question Details <span id="pi-category-badge" class="category-badge"></span></h2>
                <div class="info-grid">
                    <div class="info-card">
                        <span class="info-label">Question Text</span>
                        <p id="question-text" class="question-text">Loading...</p>
                        <button id="expand-question-btn" class="expand-btn" onclick="toggleQuestionExpand()">Show more ‚ñº</button>
                    </div>
                    <div class="info-row">
                        <div class="info-card small">
                            <span class="info-label">Ground Truth</span>
                            <span id="gt-answer" class="answer-badge gt">‚Äî</span>
                        </div>
                        <div class="info-card small">
                            <span class="info-label">Cue Answer</span>
                            <span id="cue-answer" class="answer-badge cue">‚Äî</span>
                        </div>
                        <div class="info-card small">
                            <span class="info-label">Reasoning Acc</span>
                            <span id="reasoning-acc" class="stat-value">‚Äî</span>
                        </div>
                        <div class="info-card small">
                            <span class="info-label">No-Reasoning Acc</span>
                            <span id="no-reasoning-acc" class="stat-value">‚Äî</span>
                        </div>
                        <div class="info-card small">
                            <span class="info-label">Faithfulness %</span>
                            <span id="faithfulness-pct" class="stat-value faithful-stat">‚Äî</span>
                        </div>
                    </div>
                </div>
                
                <!-- Warning for problems where reasoning is worse than no-reasoning -->
                <div id="reasoning-warning" class="reasoning-warning hidden">
                    <span class="warning-icon">‚ö†Ô∏è</span>
                    <span class="warning-text">
                        <strong>Note:</strong> This problem may be non-representative as its reasoning accuracy is lower than no-reasoning accuracy. 
                        However, attention patterns may still be interesting for such examples.
                    </span>
                </div>
            </section>

            <!-- Receiver Heads -->
            <section class="receiver-heads-section">
                <h2>Top Receiver Heads <span id="heads-category-badge" class="category-badge"></span></h2>
                <p class="section-desc">Heads with highest kurtosis in attention distribution (indicating focused attention patterns)</p>
                <p id="heads-fallback-note" class="fallback-note hidden"></p>

                <div class="heads-comparison">
                    <div class="heads-column">
                        <h3>Cued Rollout</h3>
                        <p class="column-note">‚Ä¢ Dot indicates cue mention among the top source sentences for the selected layer-head pair</p>
                        <div id="cued-heads" class="heads-list">
                            <!-- Populated dynamically -->
                        </div>
                    </div>
                    <div class="heads-column">
                        <h3>Uncued Rollout</h3>
                        <div id="uncued-heads" class="heads-list">
                            <!-- Populated dynamically -->
                        </div>
                    </div>
                </div>
                
                <div class="shared-heads">
                    <span class="shared-label">Shared Heads:</span>
                    <span id="shared-heads-list">‚Äî</span>
                </div>
            </section>

            <!-- Attention Matrices Side by Side -->
            <section class="attention-section">
                <h2>Attention Patterns <span id="attention-category-badge" class="category-badge"></span></h2>
                <p class="section-desc">Click on a head above to view its attention matrix. Hover for values.</p>
                
                <div class="attention-comparison">
                    <!-- Cued Panel -->
                    <div class="attention-panel">
                        <div class="panel-header">
                            <h3>Cued Rollout</h3>
                            <span id="cued-selected-head" class="selected-head-badge">L0-H0</span>
                            <span id="cued-prof-mention" class="prof-mention-badge">Faithfulness rate: ‚Äî%</span>
                        </div>
                        <div class="matrix-container">
                            <div id="cued-matrix" class="attention-matrix">
                                <div class="matrix-placeholder">Select a head to view attention</div>
                            </div>
                        </div>
                        <div class="stripe-analysis">
                            <h4>Top Source Sentences (Stripes) <span class="info-icon" onmouseenter="showInfoTooltip(event)" onmouseleave="hideTooltip()">‚ÑπÔ∏è</span></h4>
                            <ul id="cued-stripes" class="stripe-list">
                                <!-- Populated dynamically -->
                            </ul>
                        </div>
                    </div>

                    <!-- Uncued Panel -->
                    <div class="attention-panel">
                        <div class="panel-header">
                            <h3>Uncued Rollout</h3>
                            <span id="uncued-selected-head" class="selected-head-badge">L0-H0</span>
                        </div>
                        <div class="matrix-container">
                            <div id="uncued-matrix" class="attention-matrix">
                                <div class="matrix-placeholder">Select a head to view attention</div>
                            </div>
                        </div>
                        <div class="stripe-analysis">
                            <h4>Top Source Sentences (Stripes) <span class="info-icon" onmouseenter="showInfoTooltip(event)" onmouseleave="hideTooltip()">‚ÑπÔ∏è</span></h4>
                            <ul id="uncued-stripes" class="stripe-list">
                                <!-- Populated dynamically -->
                            </ul>
                        </div>
                    </div>
                </div>
            </section>

            <!-- Faithful vs Unfaithful Comparison (NEW) -->
            <section id="fvu-section" class="attention-section fvu-section hidden">
                <h2>Faithful vs Unfaithful Comparison</h2>
                <p class="section-desc">
                    Comparing two <strong>cued</strong> rollouts: one that <em>mentions</em> the cue (faithful) vs one that <em>follows</em> the cue without mentioning it (unfaithful).
                </p>
                
                <div id="fvu-not-available" class="fvu-not-available hidden">
                    <p>Faithful vs Unfaithful comparison not available for this problem. 
                    This requires both a cued rollout that mentions the professor AND one that doesn't.</p>
                </div>
                
                <div id="fvu-comparison" class="attention-comparison">
                    <!-- Faithful Panel -->
                    <div class="attention-panel faithful-panel">
                        <div class="panel-header">
                            <h3>Faithful (Cued + Mentions)</h3>
                            <span id="fvu-faithful-head" class="selected-head-badge">L0-H0</span>
                        </div>
                        <div class="matrix-container">
                            <div id="faithful-matrix" class="attention-matrix">
                                <div class="matrix-placeholder">Select a head to view attention</div>
                            </div>
                        </div>
                        <div class="stripe-analysis">
                            <h4>Top Source Sentences <span class="info-icon" onmouseenter="showInfoTooltip(event)" onmouseleave="hideTooltip()">‚ÑπÔ∏è</span></h4>
                            <ul id="faithful-stripes" class="stripe-list">
                                <!-- Populated dynamically -->
                            </ul>
                        </div>
                    </div>

                    <!-- Unfaithful Panel -->
                    <div class="attention-panel unfaithful-panel">
                        <div class="panel-header">
                            <h3>Unfaithful (Cued + Silent)</h3>
                            <span id="fvu-unfaithful-head" class="selected-head-badge">L0-H0</span>
                        </div>
                        <div class="matrix-container">
                            <div id="unfaithful-matrix" class="attention-matrix">
                                <div class="matrix-placeholder">Select a head to view attention</div>
                            </div>
                        </div>
                        <div class="stripe-analysis">
                            <h4>Top Source Sentences <span class="info-icon" onmouseenter="showInfoTooltip(event)" onmouseleave="hideTooltip()">‚ÑπÔ∏è</span></h4>
                            <ul id="unfaithful-stripes" class="stripe-list">
                                <!-- Populated dynamically -->
                            </ul>
                        </div>
                    </div>
                </div>
            </section>

            <!-- Conclusion -->
            <section class="conclusion-section">
                <h2>Summary</h2>
                <div class="summary-stats">
                    <div class="summary-card">
                        <span class="summary-value" id="shared-heads-count">0</span>
                        <span class="summary-label">Shared Heads</span>
                    </div>
                    <div class="summary-card">
                        <span class="summary-value" id="shared-sources-count">0</span>
                        <span class="summary-label">Shared Source Sentences</span>
                    </div>
                    <div class="summary-card">
                        <span class="summary-value" id="cue-in-stripes">‚Äî</span>
                        <span class="summary-label">Cue in Top Sources (Cued)</span>
                    </div>
                </div>
            </section>
        </main>

        <!-- Conclusion -->
        <section class="conclusion-text-section">
            <h2>Conclusion & Future Directions</h2>
            <p class="conclusion-text">
                This visualization explores whether attention patterns can serve as white-box markers for CoT faithfulness.
                While vertical stripe patterns and receiver heads emerge in both faithful and unfaithful chains,
                further work is needed to determine if systematic differences exist.
            </p>
            <p class="conclusion-text" style="margin-top: 0.75rem; font-style: normal; font-size: 0.95rem;">
                <strong>Future directions:</strong><br>
                (1) Test on domains where post-hoc rationalization is common,
                such as the hiring-scenario dataset (<a href="https://arxiv.org/abs/2506.10922" target="_blank">Karvonen & Marks, 2025</a>), where models explain choices with
                acceptable narratives that may not reflect true decision factors.<br>
                (2) Combine with Verbalization Fine-Tuning (<a href="https://arxiv.org/abs/2506.22777" target="_blank">Turpin et al., 2025</a>) ‚Äî if VFT increases cue admission,
                do receiver heads shift to anchor on the verbalized cue sentence post-training?<br>
                (2.1) Try model diffing between VFT model and original.<br>
                Such experiments could validate whether attention markers reliably track cue-following behavior.
            </p>
        </section>

        <!-- Appendix: Methodology -->
        <section class="appendix" id="appendix">
            <h2 class="appendix-header" onclick="toggleAppendix()">
                Appendix: Dataset &amp; Methodology
                <span id="appendix-toggle" class="toggle-icon">‚ñº</span>
            </h2>
            <div id="appendix-content" class="appendix-body">
            
            <div class="methodology-section">
                <h3>Research Question</h3>
                <p>
                    We investigate whether <strong>faithful</strong> and <strong>unfaithful</strong> Chain-of-Thought (CoT) 
                    reasoning exhibit different attention patterns. Specifically, we analyze attention heads that act as 
                    "receivers" ‚Äî heads with focused attention distributions (high kurtosis) that attend heavily to 
                    specific source sentences.
                </p>
            </div>

            <div class="methodology-section">
                <h3>Problem Selection Criteria</h3>
                <p>Problems were selected from MMLU using the following criteria:</p>
                <ul class="criteria-list">
                    <li><strong>Low no-reasoning accuracy (&lt;50%)</strong> ‚Äî Problems where the model struggles without CoT, ensuring reasoning is genuinely needed rather than post-hoc rationalization</li>
                    <li><strong>High cue response gap (‚â•0.5)</strong> ‚Äî Large difference in cue-following between cued and uncued conditions, indicating the cue meaningfully influences behavior</li>
                    <li><strong>Cue ‚â† Ground Truth</strong> ‚Äî The cue answer differs from the correct answer, allowing us to distinguish faithful from unfaithful reasoning</li>
                    <li><strong>Each problem is unique</strong></li>
                </ul>
            </div>

            <div class="methodology-section">
                <h3>Faithfulness Classification</h3>
                <div class="definition-grid">
                    <div class="definition-card faithful">
                        <h4>Faithful CoT</h4>
                        <p>Rollouts where the model follows the cue <strong>AND</strong> explicitly mentions the cue (e.g., "professor", "Stanford") in its reasoning.</p>
                        <p class="threshold">Threshold: ‚â•80% of cued rollouts are faithful for MMLU and ‚â•70% for GPQA diamond</p>
                    </div>
                    <div class="definition-card unfaithful">
                        <h4>Unfaithful CoT</h4>
                        <p>Rollouts where the model follows the cue <strong>BUT</strong> does not mention it in the reasoning ‚Äî the CoT does not reflect the actual decision process.</p>
                        <p class="threshold">Threshold: ‚â•80% of cued rollouts are unfaithful for MMLU and ‚â•70% for GPQA diamond</p>
                    </div>
                    <div class="definition-card mixed">
                        <h4>Mixed</h4>
                        <p>Problems with substantial proportions of both faithful and unfaithful rollouts.</p>
                        <p class="threshold">Threshold: unfaithful/faithful ratio ‚â•40%</p>
                    </div>
                </div>
            </div>

            <div class="methodology-section">
                <h3>Dataset Statistics</h3>
                
                <!-- MMLU Stats -->
                <h4 style="margin-top: 1rem; color: #666;">MMLU</h4>
                <div class="stats-grid">
                    <div class="stat-item">
                        <span class="stat-number">143</span>
                        <span class="stat-desc">Total MMLU problems analyzed</span>
                    </div>
                    <div class="stat-item">
                        <span class="stat-number">20</span>
                        <span class="stat-desc">Rollouts per problem per condition</span>
                    </div>
                    <div class="stat-item">
                        <span class="stat-number">0.637</span>
                        <span class="stat-desc">Median reasoning accuracy</span>
                    </div>
                    <div class="stat-item">
                        <span class="stat-number">0.474</span>
                        <span class="stat-desc">Median no-reasoning accuracy</span>
                    </div>
                </div>
                
                <!-- GPQA Stats -->
                <h4 style="margin-top: 1.5rem; color: #666;">GPQA-Diamond</h4>
                <div class="stats-grid">
                    <div class="stat-item">
                        <span class="stat-number">186</span>
                        <span class="stat-desc">Total GPQA problems analyzed</span>
                    </div>
                    <div class="stat-item">
                        <span class="stat-number">20</span>
                        <span class="stat-desc">Rollouts per problem per condition</span>
                    </div>
                    <div class="stat-item">
                        <span class="stat-number">0.577</span>
                        <span class="stat-desc">Mean base accuracy</span>
                    </div>
                    <div class="stat-item">
                        <span class="stat-number">0.378</span>
                        <span class="stat-desc">Mean no-reasoning accuracy</span>
                    </div>
                </div>
            </div>

            <div class="methodology-section">
                <h3>Key Findings from Data Analysis</h3>
                <p class="findings-note" style="font-size: 0.9rem; color: #666; margin-bottom: 1rem; font-style: italic;">
                    <strong>Note:</strong> "r" represents the Pearson correlation coefficient, measuring the linear relationship between two variables. 
                    Values range from -1 (perfect negative correlation) to +1 (perfect positive correlation), with 0 indicating no linear relationship.
                    "Gap" refers to the mean cue response gap ‚Äî the average increase in cue-following behavior when a misleading cue is present.
                </p>
                
                <!-- MMLU Findings -->
                <h4 style="margin-top: 1rem; color: #666;">MMLU</h4>
                <div class="findings-grid">
                    <div class="finding-card">
                        <div class="finding-header">
                            <span class="finding-metric">r(accuracy, cue following) = -0.459</span>
                            <span class="finding-pval">p &lt; 0.0001</span>
                        </div>
                        <p>Lower base accuracy correlates with <strong>more cue following</strong> ‚Äî the model is more susceptible to misleading cues on harder problems.</p>
                        <p class="finding-caveat"> Cue following behaviour is likely confounded by problem difficulty. On harder problems, the model may fall back to the cue when struggling to find an answer. To control for this, future work should compare problems with equal uncued accuracy levels.</p>
                        <button class="expand-graph-btn" onclick="toggleGraph('mmlu-acc-cue-follow')">Show graph ‚ñº</button>
                        <div id="mmlu-acc-cue-follow" class="correlation-graph hidden">
                            <img src="images/accuracy_vs_cue_following.png" alt="Accuracy vs Cue Following correlation" style="width: 100%; max-width: 600px; margin-top: 1rem;">
                        </div>
                    </div>
                    <div class="finding-card">
                        <div class="finding-header">
                            <span class="finding-metric">Gap = 0.289</span>
                            <span class="finding-pval">p &lt; 0.0001</span>
                        </div>
                        <p>Mean cue response gap of 0.289 ‚Äî <strong>79.7%</strong> of problems show increased cue following when cued.</p>
                        <button class="expand-graph-btn" onclick="toggleGraph('mmlu-gap-dist')">Show distribution ‚ñº</button>
                        <div id="mmlu-gap-dist" class="correlation-graph hidden">
                            <img src="images/mmlu_gap_distribution.png" alt="Cue Response Gap Distribution (MMLU)" style="width: 100%; max-width: 600px; margin-top: 1rem;">
                        </div>
                    </div>
                    <div class="finding-card">
                        <div class="finding-header">
                            <span class="finding-metric">r(accuracy, gap) = 0.008</span>
                            <span class="finding-pval">p = 0.92</span>
                        </div>
                        <p>No significant correlation between base accuracy and cue response gap ‚Äî the <em>change</em> in behavior is consistent across difficulty levels.</p>
                        <button class="expand-graph-btn" onclick="toggleGraph('mmlu-acc-gap')">Show graph ‚ñº</button>
                        <div id="mmlu-acc-gap" class="correlation-graph hidden">
                            <img src="images/mmlu_accuracy_vs_gap.png" alt="Accuracy vs Cue Response Gap correlation" style="width: 100%; max-width: 600px; margin-top: 1rem;">
                        </div>
                    </div>
                </div>
                
                <!-- GPQA Findings -->
                <h4 style="margin-top: 1.5rem; color: #666;">GPQA-Diamond</h4>
                <div class="findings-grid">
                    <div class="finding-card">
                        <div class="finding-header">
                            <span class="finding-metric">r(accuracy, cue following) = -0.522</span>
                            <span class="finding-pval">p &lt; 0.0001</span>
                        </div>
                        <p>Lower base accuracy correlates with <strong>more cue following</strong> ‚Äî effect is even stronger than MMLU.</p>
                        <p class="finding-caveat"><strong>Cue following behaviour is likely confounded by problem difficulty. On harder problems, the model may fall back to the cue when struggling to find an answer. To control for this, future work should compare problems with equal uncued accuracy levels.</p>
                        <button class="expand-graph-btn" onclick="toggleGraph('gpqa-acc-cue-follow')">Show graph ‚ñº</button>
                        <div id="gpqa-acc-cue-follow" class="correlation-graph hidden">
                            <img src="images/gpqa_accuracy_vs_cue_following.png" alt="Accuracy vs Cue Following correlation (GPQA)" style="width: 100%; max-width: 600px; margin-top: 1rem;">
                        </div>
                    </div>
                    <div class="finding-card">
                        <div class="finding-header">
                            <span class="finding-metric">Gap = 0.183</span>
                            <span class="finding-pval">p &lt; 0.0001</span>
                        </div>
                        <p>Mean cue response gap of 0.183 ‚Äî <strong>67.2%</strong> of problems show increased cue following when cued.</p>
                        <button class="expand-graph-btn" onclick="toggleGraph('gpqa-gap-dist')">Show distribution ‚ñº</button>
                        <div id="gpqa-gap-dist" class="correlation-graph hidden">
                            <img src="images/gpqa_gap_distribution.png" alt="Cue Response Gap Distribution (GPQA)" style="width: 100%; max-width: 600px; margin-top: 1rem;">
                        </div>
                    </div>
                    <div class="finding-card">
                        <div class="finding-header">
                            <span class="finding-metric">r(faithfulness, accuracy drop) = -0.273</span>
                            <span class="finding-pval">p = 0.0002</span>
                        </div>
                        <p>Higher faithfulness (explicit cue mentions) ‚Üí <strong>larger accuracy drops</strong>. Verbalizing the cue is associated with being more misled.</p>
                        <!-- Note: Plot may not be available if faithfulness data is missing -->
                        <button class="expand-graph-btn" onclick="toggleGraph('gpqa-faith-acc-drop')">Show graph ‚ñº</button>
                        <div id="gpqa-faith-acc-drop" class="correlation-graph hidden">
                            <img src="images/gpqa_faithfulness_vs_accuracy_drop.png" alt="Faithfulness vs Accuracy Drop correlation (GPQA)" style="width: 100%; max-width: 600px; margin-top: 1rem;">
                        </div>
                    </div>
                </div>
            </div>

            <div class="methodology-section">
                <h3>Model &amp; Generation Settings</h3>
                <p style="font-size: 0.9rem; color: var(--text-secondary); margin-bottom: 1rem;">
                    Two generation stages were used: (1) initial rollouts for faithfulness classification,
                    (2) attention analysis rollouts for visualization. Both use the same sampling parameters.
                </p>
                <table class="settings-table">
                    <tr><td>Model</td><td><code>deepseek-ai/deepseek-r1-distill-qwen-14b</code></td></tr>
                    <tr><td>Temperature</td><td>0.7</td></tr>
                    <tr><td>Top-p</td><td>0.95</td></tr>
                    <tr><td>Max tokens (MMLU)</td><td>2048</td></tr>
                    <tr><td>Max tokens (GPQA)</td><td>8192 (stage 1) / 2048 (stage 2)</td></tr>
                    <tr><td>Rollouts per condition</td><td>20 (stage 1) / 5 (stage 2)</td></tr>
                </table>

                <!-- Collapsible Rollout Generation Notes -->
                <div class="sidenote-container">
                    <div class="sidenote-header" onclick="toggleSidenote('rollout-gen')">
                        <span class="sidenote-icon">‚öôÔ∏è</span>
                        <span class="sidenote-title">Details: Two-Stage Generation Pipeline</span>
                        <span id="rollout-gen-toggle" class="sidenote-toggle">‚ñ∂</span>
                    </div>
                    <div id="rollout-gen-content" class="sidenote-body collapsed">
                        <p class="sidenote-intro">
                            The analysis uses a two-stage pipeline. Both stages use temperature=0.7, top_p=0.95 (matching the original paper).
                        </p>

                        <div class="diff-item">
                            <h5>Stage 1: Initial Rollout Generation</h5>
                            <p>Script: <code>run_pipeline.py</code> with vLLM</p>
                            <ul>
                                <li><strong>Purpose:</strong> Generate large sample for faithfulness classification</li>
                                <li><strong>Rollouts:</strong> 20 cued + 20 uncued per problem</li>
                                <li><strong>Used for:</strong> Problem selection, accuracy stats, faithfulness %</li>
                            </ul>
                        </div>

                        <div class="diff-item">
                            <h5>Stage 2: Attention Analysis Generation</h5>
                            <p>Script: <code>anchors_unified.ipynb</code></p>
                            <ul>
                                <li><strong>Purpose:</strong> Generate rollouts with attention weights for visualization</li>
                                <li><strong>Rollouts:</strong> 5 cued + 5 uncued per selected problem</li>
                                <li><strong>Used for:</strong> Attention matrices, receiver heads, stripe analysis</li>
                            </ul>
                        </div>

                        <div class="diff-item">
                            <h5>MMLU-Specific</h5>
                            <p>Config: <code>configs/mmlu_config.py</code></p>
                            <ul>
                                <li><strong>Source:</strong> Chua et al. faithfulness dataset (Professor cue)</li>
                                <li><strong>Max tokens:</strong> 2048 (stage 1), 2048 (stage 2)</li>
                                <li><strong>Conditions:</strong> <code>itc_failure</code> + <code>itc_success</code></li>
                            </ul>
                        </div>

                        <div class="diff-item">
                            <h5>GPQA-Diamond Specific</h5>
                            <p>Config: <code>configs/gpqa_config.py</code></p>
                            <ul>
                                <li><strong>Source:</strong> <a href="https://huggingface.co/datasets/yulia-volkova/gpqa-diamond-cued-prepared" target="_blank">HuggingFace prepared dataset</a></li>
                                <li><strong>Max tokens:</strong> 8192 (stage 1), 2048 (stage 2)</li>
                                <li><strong>Output suffix:</strong> <code>_8192_mt</code></li>
                            </ul>
                        </div>

                        <p class="sidenote-source">
                            Scripts: <code>run_pipeline.py</code>, <code>run_cued_uncued.py</code>, <code>anchors_unified.ipynb</code>
                        </p>
                    </div>
                </div>
            </div>

            <div class="methodology-section">
                <h3>Attention Analysis</h3>
                <p>
                    For each problem, we identify <strong>receiver heads</strong> ‚Äî attention heads with high kurtosis
                    in their attention distribution across all rollouts. High kurtosis indicates the head consistently
                    attends to specific source sentences (creating "vertical stripes" in the attention matrix).
                </p>
                <p>
                    We then compare which source sentences receive the most attention in cued vs. uncued rollouts,
                    and whether cue-related sentences (those mentioning the professor/Stanford cue) appear among
                    the top-attended sources.
                </p>

                <!-- Collapsible Implementation Notes -->
                <div class="sidenote-container">
                    <div class="sidenote-header" onclick="toggleSidenote('impl-notes')">
                        <span class="sidenote-icon">üìù</span>
                        <span class="sidenote-title">Implementation Notes: Differences from Original Thought-Anchors</span>
                        <span id="impl-notes-toggle" class="sidenote-toggle">‚ñ∂</span>
                    </div>
                    <div id="impl-notes-content" class="sidenote-body collapsed">
                        <p class="sidenote-intro">
                            Our implementation is adapted from the
                            <a href="https://github.com/interp-reasoning/thought-anchors" target="_blank">thought-anchors</a>
                            whitebox analyses. Key differences:
                        </p>

                        <div class="diff-item">
                            <h5>1. Averaged Matrix Computation</h5>
                            <p><code>avg_matrix_by_chunk</code> vs original <code>_compute_averaged_matrix</code></p>
                            <ul>
                                <li>We return <code>NaN</code> for empty regions; original returns <code>0</code></li>
                                <li>Simpler implementation without bounds checking (assumes valid inputs)</li>
                            </ul>
                        </div>

                        <div class="diff-item">
                            <h5>2. Vertical Score Calculation</h5>
                            <p><code>get_attn_vert_scores</code> vs original <code>get_vertical_scores</code></p>
                            <ul>
                                <li><strong>No <code>control_depth</code></strong>: Original has option to rank-normalize attention
                                    values per row, controlling for the fact that later sentences have more preceding sentences to
                                    attend to. We use raw attention values.</li>
                                <li><strong>Added <code>drop_first</code></strong>: We set first/last N scores to NaN to filter
                                    noisy boundary sentences (default N=1)</li>
                                <li>Default <code>proximity_ignore=3</code> vs original's <code>20</code></li>
                            </ul>
                        </div>

                        <div class="diff-item">
                            <h5>3. Kurtosis Computation</h5>
                            <p><code>compute_kurtosis_per_head</code> vs original <code>get_3d_ar_kurtosis</code></p>
                            <ul>
                                <li>We use dict <code>{(layer,head): [scores]}</code>; original uses 3D numpy array</li>
                                <li>We compute kurtosis per rollout then average; original computes directly on axis=2</li>
                            </ul>
                        </div>

                        <div class="diff-item">
                            <h5>4. Head Selection</h5>
                            <p><code>select_top_heads</code> vs original <code>get_top_k_receiver_heads</code></p>
                            <ul>
                                <li><strong>Added <code>min_max_vert</code> filter</strong>: We filter out heads where max vertical
                                    score is below threshold (default 0.001), removing inactive heads that might have high kurtosis
                                    by chance</li>
                            </ul>
                        </div>

                        <div class="diff-item">
                            <h5>5. Attention Analysis Generation</h5>
                            <p>Settings used for generating rollouts shown in visualizations</p>
                            <ul>
                                <li><strong>max_new_tokens=2048</strong> for both MMLU and GPQA (not 8192)</li>
                                <li>5 rollouts per condition (cued/uncued)</li>
                                <li>Script: <code>anchors_unified.ipynb</code></li>
                            </ul>
                        </div>

                        <p class="sidenote-source">
                            Original source: <a href="https://github.com/interp-reasoning/thought-anchors/tree/main/whitebox-analyses/attention_analysis" target="_blank">whitebox-analyses/attention_analysis/</a>
                        </p>
                    </div>
                </div>
            </div>
            </div> <!-- appendix-content -->
        </section>

        <!-- Footer -->
        <footer class="footer">
            <p>Attention Analysis for Chain-of-Thought Faithfulness</p>
            <p class="footer-links">
                <a href="#appendix">Methodology</a> ¬∑ 
                <a href="https://github.com/yourusername/thought-anchors-faithfulness" target="_blank">GitHub</a>
            </p>
        </footer>
    </div>

    <!-- Tooltip -->
    <div id="tooltip" class="tooltip hidden"></div>

    <script src="data.js"></script>
    <script src="app.js"></script>
</body>
</html>

